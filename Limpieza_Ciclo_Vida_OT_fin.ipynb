{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es_ES'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de librerias a usar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'es_ES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga el archivo a limpiar, en un comienzo este archivo tenia espacios vacios, con la parte comentada se corrige ese error\n",
    "path = '../Datos/XXEJE_EAM___Ciclo_de_vida_de_ó_010222.xls'\n",
    "with open(path, 'rt', encoding='utf-8') as myfile:\n",
    "    data = myfile.read()#.replace('</span><br/><span class=\"c62\">', ' ').replace('</span><br/><br/><span class=\"c62\">', ' ').replace('</span><br/><br/><br/><span class=\"c62\">', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora se crea el DataFrame para trabajar\n",
    "df_ori = pd.read_html(data, header=0)\n",
    "df_cvo = pd.DataFrame(df_ori[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca se eliminan los duplicados, y se crean columnas que se llenaran mas adelante, ademas, se separa la informacion de la columna 'Grupo de Activos' y se completa la informacion del tipo de OT, principal o secundaria\n",
    "df_cvo = pd.DataFrame(df_ori[0])\n",
    "\n",
    "df_cvo.drop_duplicates(inplace = True)\n",
    "df_cvo.insert(loc=2, column='PPU_MMU', value=None)\n",
    "df_cvo.insert(loc=5, column='Tipo Ot', value='Principal')\n",
    "df_cvo.insert(loc=6, column='Sistema', value=None)\n",
    "\n",
    "sist = ['Grupo Motopropulsor', 'Alimentacion De Combustible', 'Frenos', 'Rodadura', 'Direccion y Conduccion', 'Suspencion', 'Generacion e Iluminacion', 'Indicacion y Registro', 'Anfibio y Vadeo', 'Guiado de Armamento', 'Observacion y Control de Fuego', 'Armamento Principal', 'No Identificado 13', 'Plataforma Hidraulica', 'Plataforma Estructural', 'Equipamento Zapador / Recuperador', 'Extincion de Incendios', 'Acondicionamiento de Aire', 'Lanza Fumigenos', 'Estructura', 'Equipamiento Estructura', 'No Identificado 22', 'Comunicaciones']\n",
    "\n",
    "for i, sis in enumerate(sist):\n",
    "    df_cvo['Sistema'] = np.where(((df_cvo['Grupo De Activos']=='GR_SIS.02.0'+str(i+1).zfill(2)) | (df_cvo['Grupo De Activos'].str.contains('GR_SUB.02.0'+str(i+1).zfill(2)))), sis, df_cvo['Sistema'])\n",
    "    \n",
    "df_cvo['Numero Ot Principal'] = np.where(df_cvo['Numero Ot Principal'].str.contains('No tiene'),None,df_cvo['Numero Ot Principal'])\n",
    "df_cvo['Tipo Ot'] = np.where(df_cvo['Numero Ot Principal'].isnull(),df_cvo['Tipo Ot'],'Secundaria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda se completa la infora de la columna 'PPU_MMU', se separa la informacion de la columna 'Descripcion Activo', donde su primer entrada es la patente o mmu del vehiculo. Se ocupan estos try and except, porque algunos vehiculos no tienen patente o mmu, y se debe dejar en blanco\n",
    "df_cvo['PPU_MMU'] = df_cvo['Descripcion Activo'].str.split('_', expand = True)[0]\n",
    "b=0\n",
    "for i, n in enumerate(df_cvo['PPU_MMU']):\n",
    "    try:\n",
    "        if not (re.match(r'[a-zA-Z0-9]{1,4}-[a-zA-Z0-9]{1,4}$', n)):\n",
    "            m = df_cvo.loc[i,'Numero Activo'][4:]\n",
    "            df_cvo.loc[i,'PPU_MMU'] = m # df_cvo.loc[i,'Numero Activo'][4:]\n",
    "    except:\n",
    "        b=1\n",
    "for i, n in enumerate(df_cvo['PPU_MMU']):\n",
    "    try:\n",
    "        if not (re.match(r'[a-zA-Z0-9]{1,4}-[a-zA-Z0-9]{1,4}$', n)):\n",
    "            df_cvo.loc[i,'PPU_MMU'] = df_cvo.loc[i,'Descripcion Activo'][:7]\n",
    "    except:\n",
    "        b=1\n",
    "\n",
    "for i, n in enumerate(df_cvo['PPU_MMU']):\n",
    "    try:\n",
    "        if not (re.match(r'[a-zA-Z0-9]{1,4}-[a-zA-Z0-9]{1,4}$', n)):\n",
    "            df_cvo.loc[i,'PPU_MMU'] = 'SinNumero'\n",
    "        else:\n",
    "            b=2\n",
    "    except:\n",
    "        b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora se cargan los archivos auxliares que permiten completar la informacion\n",
    "df_rs = pd.read_csv('Valores_OT_Asoc_SIC.csv', header =0)\n",
    "df_bdvehic = pd.read_csv('Clean_Bd_Vehic.csv', encoding='latin-1')\n",
    "df_cod_org = pd.read_csv('Codigo_Organizacion.csv', sep=';')\n",
    "\n",
    "df_bdvehic.rename(columns={'MMU/PPU':'PPU_MMU'}, inplace=True)\n",
    "df_bdvehic['PPU_MMU'] = df_bdvehic['PPU_MMU'].astype(str)\n",
    "df_bdvehic.drop_duplicates(inplace = True, subset = ['PPU_MMU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizo una estandarizacion de los nombres de las columnas\n",
    "\n",
    "df_rs.columns = df_rs.columns.str.replace(' ', '')\n",
    "df_cvo.columns = df_cvo.columns.str.replace(' ', '')\n",
    "\n",
    "df_rs.columns = df_rs.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_cvo.columns = df_cvo.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el DataFrame que se va a utilizar para completar la informacion, usando los nombres de columnas que se presentan aca\n",
    "column_names = ['Numero_OT', 'OT_Principal', 'Tipo_OT', 'Estado_OT', 'PPU_MMU', 'Total', 'Desc', 'Marca', 'Modelo', 'Nom', 'Ele_Comp', 'Desc_Falla', 'Cod_Org', 'Nom_Org', 'Cod_Taller', 'UAC', 'UR', 'Tipo_Mant', 'Tipo_Comb', 'Sistema', 'Fec_Creacion', 'Fec_Final', 'Fec_Liberacion', 'Fec_Cierre', 'Year', 'Fabricat_Year']\n",
    "\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.columns = df.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copio la informacion del DataFrame principal a al DataFrame final\n",
    "df[['Numero_OT', 'OT_Principal', 'Tipo_OT', 'Estado_OT', 'PPU_MMU', 'Ele_Comp', 'Desc_Falla', 'Cod_Org', 'Cod_Taller', 'Tipo_Mant', 'Sistema', 'Fec_Solicitud' ,'Fec_Creacion', 'Fec_Final', 'Fec_Liberacion', 'Fec_Cierre']] = df_cvo[['NumeroOt', 'NumeroOtPrincipal', 'TipoOt', 'Estado', 'PPU_MMU', 'GrupoDeActivos', 'DescripcionOt', 'NombreUR', 'CodigoTaller', 'TipoMantenimiento', 'Sistema', 'Fechasolicitud','FechaCreacion', 'FechaFinalizacion', 'FechaLiberacion', 'FechaCierre']]\n",
    "df['PPU_MMU'] = df['PPU_MMU'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se completa la informacion de la columna 'Tipo OT' para que solo contenga las opciones 'Principal' o 'Secundaria'\n",
    "df['Tipo_OT'] = np.where(df['OT_Principal'].str.contains('No Tiene'), 'Principal', df['Tipo_OT'])\n",
    "df['Tipo_OT'] = np.where(df['OT_Principal'].str.contains('OT'), 'Secundaria', df['Tipo_OT'])\n",
    "\n",
    "mp = {'MPI', 'MPC'}\n",
    "df.loc[df.Tipo_Mant.isin(mp), 'Tipo_OT'] = 'Principal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion permite combinar la informacion de los archivos auxiliares, para que se pueda completar la informacion del DataFrame final, la hice como funcion ya que se repite un par de veces\n",
    "def right_join_test(left_db, right_db, left_col, left_merge_cols, right_col, right_merge_cols):\n",
    "    left_temp_df = left_db.copy()\n",
    "    left_temp_df[left_col] = left_temp_df[left_col].astype(str)\n",
    "    right_temp_df = right_db[right_col].astype(str)\n",
    "    right_db[right_merge_cols] = pd.merge(left_temp_df, right_temp_df, left_on=left_col, right_on=right_col, how='right', indicator=True)[left_merge_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando la funcion, combino la informacion del archivo auxiliar que contiene la informacion de los vehiculos con la informacion del DataFrame principal\n",
    "left_cols = ['Descripción', 'Marca', 'Modelo', 'UAC', 'UR', 'Tipo Patente', 'Combustible', 'Función', 'Año Fabricación']\n",
    "right_cols = ['Desc', 'Marca', 'Modelo', 'UAC', 'UR', 'Nom', 'Tipo_Comb', 'Ele_Comp', 'Fabricat_Year']\n",
    "right_join_test(df_bdvehic, df, 'PPU_MMU', left_cols, 'PPU_MMU', right_cols)\n",
    "df['Ele_Comp'].replace(np.nan, 'NO APLICA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora se vuelve a usar la funcion, esta vez para valorizar las OTs, con la informacion del reporte de SIC asociadas a OT\n",
    "left_cols = ['Total']\n",
    "right_cols = ['Total']\n",
    "right_join_test(df_rs, df, 'NroOt', left_cols, 'Numero_OT', right_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente, usando el codigo de organización, le asigno nombres a las organizaciones, para que no aparezcan como código y sean mas entendibles\n",
    "left_cols = 'Nombre'\n",
    "right_cols = 'Nom_Org'\n",
    "right_join_test(df_cod_org, df, 'Codigo', left_cols, 'Cod_Org', right_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como preparación para usar las fechas como formato 'DateTime', hago la siguiente conversion de los meses, ya que estos son los que se reconocen al usar 'esp' como locale\n",
    "df['Fec_Solicitud'].replace('ENE', 'ene.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('FEB', 'feb.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('MAR', 'mar.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('ABR', 'abr.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('MAY', 'may.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('JUN', 'jun.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('JUL', 'jul.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('AGO', 'ago.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('SEP', 'sep.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('OCT', 'oct.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('NOV', 'nov.', regex=True, inplace=True)\n",
    "df['Fec_Solicitud'].replace('DIC', 'dic.', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca convierto las fechas a formato 'DateTime', las fechas en el ciclo 'for' tienen un formato identico, por lo que es posible convertirlas de una sola vez, la 'Fec_Solicitud' viene con otro formato, por lo que se convierte de manera solitaria\n",
    "for i in df[['Fec_Creacion', 'Fec_Final', 'Fec_Liberacion', 'Fec_Cierre']]:\n",
    "    df.loc[:, i] = pd.to_datetime(df.loc[:, i], errors='coerce', format='%Y/%m/%d')\n",
    "    \n",
    "df['Fec_Solicitud'] = pd.to_datetime(df['Fec_Solicitud'], errors='coerce', format='%d-%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lanzet\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:5233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "# Como ultimo paso, se selecciona la fecha de la OT, como la minima entre todas las fechas en el DataFrame\n",
    "df_temp = df[[ 'Fec_Creacion', 'Fec_Final', 'Fec_Liberacion', 'Fec_Cierre']]\n",
    "df_temp.replace(np.datetime64('NaT'), str(pd.to_datetime('today').normalize().year), inplace=True)\n",
    "df['Year'] = [np.amin(np.array([row.Fec_Creacion.year,row.Fec_Final.year,row.Fec_Liberacion.year,row.Fec_Cierre.year])) for _, row in df_temp.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = Path.cwd() / \"output.xlsx\"\n",
    "writer = pd.ExcelWriter(out_file, engine = 'xlsxwriter', datetime_format='yyyy-mm-dd', date_format='yyyy-mm-dd')\n",
    "df.to_excel(writer, index = False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abd71ca0273cee8f8830c46ec1e03309f3a1a65fe5bd29f380243a6172077fef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
